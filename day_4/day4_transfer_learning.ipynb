{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "4_transfer_learning_tutorial.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T13:05:02.320549Z",
          "start_time": "2021-09-14T13:05:01.658531Z"
        },
        "id": "DU8O7-45pUdB"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiOVR5aZqUZF"
      },
      "source": [
        "# ì´ì›ƒì§‘ í† í† ì¹˜ íŒŒì´í† ì¹˜ : Day 4\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k53Uy-00qZ_i"
      },
      "source": [
        "<div class=\"alert alert-info\"><p>\n",
        "    ğŸ“¢ í•´ë‹¹ ê²Œì‹œë¬¼ì€ íŒŒì´í† ì¹˜ ê³µì‹ íŠœí† ë¦¬ì–¼ ì¤‘  <a href=\"https://tutorials.pytorch.kr/beginner/transfer_learning_tutorial.html\">ì»´í“¨í„° ë¹„ì „(VISION)ì„ ìœ„í•œ ì „ì´í•™ìŠµ(TRANSFER LEARNING)</a>ë¥¼ ì¬êµ¬ì„±í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "</p></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PGUy2XYpUdI"
      },
      "source": [
        "**Author**: [Sasank Chilamkurthy](https://chsasank.github.io)<br>\n",
        "**ë²ˆì—­**: [ë°•ì •í™˜](http://github.com/9bow)<br>\n",
        "**í¸ì§‘**: ì •ìˆ˜í¬\n",
        "\n",
        "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ì „ì´í•™ìŠµ(Transfer Learning)ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ í•©ì„±ê³± ì‹ ê²½ë§ì„ ì–´ë–»ê²Œ í•™ìŠµì‹œí‚¤ëŠ”ì§€ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤. ì „ì´í•™ìŠµì— ëŒ€í•´ì„œëŠ” [CS231n ë…¸íŠ¸](http://cs231n.github.io/transfer-learning/)ì—ì„œ ë” ë§ì€ ë‚´ìš©ì„ ì½ì–´ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ„ ë…¸íŠ¸ë¥¼ ì¸ìš©í•´ë³´ë©´,\n",
        "\n",
        "\n",
        "> ì‹¤ì œë¡œ ì¶©ë¶„í•œ í¬ê¸°ì˜ ë°ì´í„°ì…‹ì„ ê°–ì¶”ê¸°ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë“œë¬¼ê¸° ë•Œë¬¸ì—, (ë¬´ì‘ìœ„ ì´ˆê¸°í™”ë¥¼ í†µí•´) ë§¨ ì²˜ìŒë¶€í„° í•©ì„±ê³± ì‹ ê²½ë§(Convolutional Network) ì „ì²´ë¥¼ í•™ìŠµí•˜ëŠ” ì‚¬ëŒì€ ë§¤ìš° ì ìŠµë‹ˆë‹¤. ëŒ€ì‹ , ë§¤ìš° í° ë°ì´í„°ì…‹(ì˜ˆ. 100ê°€ì§€ ë¶„ë¥˜ì— ëŒ€í•´ 120ë§Œê°œì˜ ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ImageNet)ì—ì„œ í•©ì„±ê³± ì‹ ê²½ë§(ConvNet)ì„ ë¯¸ë¦¬ í•™ìŠµí•œ í›„, ì´ í•©ì„±ê³± ì‹ ê²½ë§ì„ ê´€ì‹¬ìˆëŠ” ì‘ì—…ì„ ìœ„í•œ ì´ˆê¸° ì„¤ì • ë˜ëŠ” ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œê¸°(fixed feature extractor)ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "ì´ëŸ¬í•œ ì „ì´í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤ì˜ ì£¼ìš”í•œ 2ê°€ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "\n",
        "-  **í•©ì„±ê³± ì‹ ê²½ë§ì˜ ë¯¸ì„¸ì¡°ì •(finetuning)**: ë¬´ì‘ìœ„ ì´ˆê¸°í™” ëŒ€ì‹ , ì‹ ê²½ë§ì„\n",
        "   ImageNet 1000 ë°ì´í„°ì…‹ ë“±ìœ¼ë¡œ ë¯¸ë¦¬ í•™ìŠµí•œ ì‹ ê²½ë§ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. í•™ìŠµì˜ ë‚˜ë¨¸ì§€ ê³¼ì •ë“¤ì€ í‰ìƒì‹œì™€ ê°™ìŠµë‹ˆë‹¤.\n",
        "-  **ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œì¨ì˜ í•©ì„±ê³± ì‹ ê²½ë§**: ì—¬ê¸°ì„œëŠ” ë§ˆì§€ë§‰ì— ì™„ì „íˆ ì—°ê²°ëœ ê³„ì¸µì„ ì œì™¸í•œ ëª¨ë“  ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •í•©ë‹ˆë‹¤. ì´ ë§ˆì§€ë§‰ì˜ ì™„ì „íˆ ì—°ê²°ëœ ê³„ì¸µì€ ìƒˆë¡œìš´ ë¬´ì‘ìœ„ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°–ëŠ” ê³„ì¸µìœ¼ë¡œ ëŒ€ì²´ë˜ì–´ ì´ ê³„ì¸µë§Œ í•™ìŠµí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T13:06:00.496724Z",
          "start_time": "2021-09-14T13:06:00.431630Z"
        },
        "id": "-uCayuV-pUdR"
      },
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # ëŒ€í™”í˜• ëª¨ë“œ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoC-SSbxpUdU"
      },
      "source": [
        "## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "---\n",
        "\n",
        "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ `torchvision`ê³¼ `torch.utils.data` íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œ í’€ê³ ì í•˜ëŠ” ë¬¸ì œëŠ” **ê°œë¯¸** ì™€ **ë²Œ** ì„ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê°œë¯¸ì™€ ë²Œ ê°ê°ì˜ í•™ìŠµìš© ì´ë¯¸ì§€ëŠ” ëŒ€ëµ 120ì¥ ì •ë„ ìˆê³ , 75ê°œì˜ ê²€ì¦ìš© ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë§¨ ì²˜ìŒë¶€í„° í•™ìŠµì„ í•œë‹¤ë©´ ì´ëŠ” ì¼ë°˜í™”í•˜ê¸°ì—ëŠ” ì•„ì£¼ ì‘ì€ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ì „ì´í•™ìŠµì„ í•  ê²ƒì´ë¯€ë¡œ, ì¼ë°˜í™”ë¥¼ ì œë²• ì˜ í•  ìˆ˜ ìˆì„\n",
        "ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ ë°ì´í„°ì…‹ì€ ImageNetì˜ ì•„ì£¼ ì‘ì€ ì¼ë¶€ì…ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ’™ ë°ì´í„°ë¥¼ [ì—¬ê¸°](https://download.pytorch.org/tutorial/hymenoptera_data.zip)ì—ì„œ ë‹¤ìš´ë¡œë“œ ë°›ì•„ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì••ì¶•ì„ í‘¸ì‹­ì‹œì˜¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUfnCBsKrihc"
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "!unzip hymenoptera_data -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T13:05:56.083077Z",
          "start_time": "2021-09-14T13:05:56.047174Z"
        },
        "id": "ITXQbHm6pUdW"
      },
      "source": [
        "# í•™ìŠµì„ ìœ„í•´ ë°ì´í„° ì¦ê°€(augmentation) ë° ì¼ë°˜í™”(normalization)\n",
        "# ê²€ì¦ì„ ìœ„í•œ ì¼ë°˜í™”\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5i7_P-NpUda"
      },
      "source": [
        "### ì¼ë¶€ ì´ë¯¸ì§€ ì‹œê°í™”í•˜ê¸°\n",
        "\n",
        "ë°ì´í„° ì¦ê°€ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ì¼ë¶€ í•™ìŠµìš© ì´ë¯¸ì§€ë¥¼ ì‹œê°í™”í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGGowq6PpUdb"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # ê°±ì‹ ì´ ë  ë•Œê¹Œì§€ ì ì‹œ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "# í•™ìŠµ ë°ì´í„°ì˜ ë°°ì¹˜ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# ë°°ì¹˜ë¡œë¶€í„° ê²©ì í˜•íƒœì˜ ì´ë¯¸ì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_SudEIHpUdc"
      },
      "source": [
        "## ëª¨ë¸ í•™ìŠµí•˜ê¸°\n",
        "--------------\n",
        "\n",
        "ì´ì œ ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ ì¼ë°˜ í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ë‹¤ìŒ ë‚´ìš©ë“¤ì„\n",
        "ì„¤ëª…í•©ë‹ˆë‹¤:\n",
        "\n",
        "-  í•™ìŠµë¥ (learning rate) ê´€ë¦¬(scheduling)\n",
        "-  ìµœì ì˜ ëª¨ë¸ êµ¬í•˜ê¸°\n",
        "\n",
        "ì•„ë˜ì—ì„œ ``scheduler`` ë§¤ê°œë³€ìˆ˜ëŠ” ``torch.optim.lr_scheduler`` ì˜ LR ìŠ¤ì¼€ì¥´ëŸ¬\n",
        "ê°ì²´(Object)ì…ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vm7lzQzpUdd"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # ê° ì—í­(epoch)ì€ í•™ìŠµ ë‹¨ê³„ì™€ ê²€ì¦ ë‹¨ê³„ë¥¼ ê°–ìŠµë‹ˆë‹¤.\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n",
        "            else:\n",
        "                model.eval()   # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # ë°ì´í„°ë¥¼ ë°˜ë³µ\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # ë§¤ê°œë³€ìˆ˜ ê²½ì‚¬ë„ë¥¼ 0ìœ¼ë¡œ ì„¤ì •\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # ìˆœì „íŒŒ\n",
        "                # í•™ìŠµ ì‹œì—ë§Œ ì—°ì‚° ê¸°ë¡ì„ ì¶”ì \n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1) # argmax\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # í•™ìŠµ ë‹¨ê³„ì¸ ê²½ìš° ì—­ì „íŒŒ + ìµœì í™”\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # í†µê³„\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # ëª¨ë¸ì„ ê¹Šì€ ë³µì‚¬(deep copy)í•¨\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # ê°€ì¥ ë‚˜ì€ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜´\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIo0CoEdpUde"
      },
      "source": [
        "### ëª¨ë¸ ì˜ˆì¸¡ê°’ ì‹œê°í™”í•˜ê¸°\n",
        "\n",
        "\n",
        "ì¼ë¶€ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ì„ ë³´ì—¬ì£¼ëŠ” ì¼ë°˜í™”ëœ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0V5W81tpUdf"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPgH5MHPpUdf"
      },
      "source": [
        "## í•©ì„±ê³± ì‹ ê²½ë§ ë¯¸ì„¸ì¡°ì •(finetuning)\n",
        "----------------------------------\n",
        "\n",
        "ë¯¸ë¦¬ í•™ìŠµí•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¨ í›„ ë§ˆì§€ë§‰ì˜ ì™„ì „íˆ ì—°ê²°ëœ ê³„ì¸µì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQMOoDFfpUdg"
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "print(model_ft)\n",
        "print(f'num_ftrs : {num_ftrs}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xKDhX2EMu18"
      },
      "source": [
        "# ì—¬ê¸°ì„œ ê° ì¶œë ¥ ìƒ˜í”Œì˜ í¬ê¸°ëŠ” 2ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "# ë˜ëŠ”, nn.Linear(num_ftrs, len (class_names))ë¡œ ì¼ë°˜í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "model_ft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXGaCSsBMzIH"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë“¤ì´ ìµœì í™”ë˜ì—ˆëŠ”ì§€ ê´€ì°°\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 7 ì—í­ë§ˆë‹¤ 0.1ì”© í•™ìŠµë¥  ê°ì†Œ\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY_D9Vj3pUdh"
      },
      "source": [
        "### í•™ìŠµ ë° í‰ê°€í•˜ê¸°\n",
        "\n",
        "CPUì—ì„œëŠ” 15-25ë¶„ ê°€ëŸ‰, GPUì—ì„œëŠ” 1ë¶„ë„ ì´ë‚´ì˜ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFE_KJyxpUdh"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7dWSikJpUdh"
      },
      "source": [
        "visualize_model(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU9IsIiXpUdi"
      },
      "source": [
        "## ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œì¨ì˜ í•©ì„±ê³± ì‹ ê²½ë§\n",
        "---------------------------------------\n",
        "\n",
        "ì´ì œ, ë§ˆì§€ë§‰ ê³„ì¸µì„ ì œì™¸í•œ ì‹ ê²½ë§ì˜ ëª¨ë“  ë¶€ë¶„ì„ ê³ ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "``requires_grad == False`` ë¡œ ì„¤ì •í•˜ì—¬ ë§¤ê°œë³€ìˆ˜ë¥¼ ê³ ì •í•˜ì—¬ ``backward()`` ì¤‘ì—\n",
        "ê²½ì‚¬ë„ê°€ ê³„ì‚°ë˜ì§€ ì•Šë„ë¡ í•´ì•¼í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ì— ëŒ€í•œ ë¬¸ì„œëŠ”\n",
        "[ì—¬ê¸°](http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward)\n",
        "ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zHWabtApUdi"
      },
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ìƒˆë¡œ ìƒì„±ëœ ëª¨ë“ˆì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ê¸°ë³¸ê°’ì´ requires_grad=True ì„\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ì´ì „ê³¼ëŠ” ë‹¤ë¥´ê²Œ ë§ˆì§€ë§‰ ê³„ì¸µì˜ ë§¤ê°œë³€ìˆ˜ë“¤ë§Œ ìµœì í™”ë˜ëŠ”ì§€ ê´€ì°°\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 7 ì—í­ë§ˆë‹¤ 0.1ì”© í•™ìŠµë¥  ê°ì†Œ\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoMQu-nupUdi"
      },
      "source": [
        "### í•™ìŠµ ë° í‰ê°€í•˜ê¸°\n",
        "\n",
        "CPUì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²½ìš° ì´ì „ê³¼ ë¹„êµí–ˆì„ ë•Œ ì•½ ì ˆë°˜ ê°€ëŸ‰ì˜ ì‹œê°„ë§Œì´ ì†Œìš”ë  ê²ƒì…ë‹ˆë‹¤.\n",
        "ì´ëŠ” ëŒ€ë¶€ë¶„ì˜ ì‹ ê²½ë§ì—ì„œ ê²½ì‚¬ë„ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ,\n",
        "ìˆœì „íŒŒëŠ” ê³„ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiGkbSfDpUdj"
      },
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ttOQrHpUdk"
      },
      "source": [
        "visualize_model(model_conv)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_levHDQpUdk"
      },
      "source": [
        "ë” ë°°ì›Œë³¼ ë‚´ìš©\n",
        "-----------------\n",
        "\n",
        "ì „ì´í•™ìŠµì˜ ì‘ìš© ì‚¬ë¡€(application)ë“¤ì„ ë” ì•Œì•„ë³´ë ¤ë©´,\n",
        ":doc:`/intermediate/quantized_transfer_learning_tutorial` ì„ ì°¸ì¡°í•´ë³´ì„¸ìš”.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}